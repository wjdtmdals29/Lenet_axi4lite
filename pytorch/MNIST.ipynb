{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\newb\\AppData\\Local\\Temp\\ipykernel_10848\\2752403819.py:64: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.278585\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.285116\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.297377\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.243494\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.229906\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.199277\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.169067\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.118395\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 1.968381\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 1.788344\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1.678912\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 1.304346\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 1.202735\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.910581\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.855309\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.680743\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.608643\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.800273\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.757894\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.571866\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.639096\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.582143\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.434887\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.555898\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.525354\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.385118\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.391940\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.411123\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.466574\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.552435\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.331770\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.385912\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.261684\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.455402\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.398468\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.407215\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.247325\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.508770\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.412230\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.284449\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.389847\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.349213\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.171513\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.353102\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.509399\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.267470\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.252248\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.261509\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.331778\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.331213\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.315651\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.318065\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.455170\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.291507\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.448751\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.248761\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.386462\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.306793\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.266687\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.240541\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.268465\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.269182\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.278004\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.342118\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.240152\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.357742\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.226376\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.197425\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.311277\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.387279\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.392834\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.237163\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.347700\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.367926\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.410088\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.241360\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.338222\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.263472\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.202440\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.634264\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.273761\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.138085\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.276703\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.135214\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.240093\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.130211\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.236385\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.214266\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.233617\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.092158\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.215550\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.180690\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.324837\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.138248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\newb\\AppData\\Local\\Temp\\ipykernel_10848\\2752403819.py:93: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  data, target = Variable(data, volatile=True), Variable(target)\n",
      "c:\\Users\\newb\\anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.2195, Accuracy: 9340/10000 (93%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.326037\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.153194\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.170832\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.130829\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.085438\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.118484\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.151981\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.095058\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.127792\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.129017\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.277412\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.198916\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.125118\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.225470\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.057302\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.156341\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.183331\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.350255\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.398225\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.172958\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.130664\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.050796\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.177867\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.289648\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.184251\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.147805\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.116345\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.158810\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.209341\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.283242\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.068891\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.102633\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.085673\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.057715\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.126118\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.086318\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.340528\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.224669\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.262495\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.240329\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.240907\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.126548\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.224589\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.222452\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.174802\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.251819\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.188660\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.084852\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.224965\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.204244\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.081986\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.371180\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.333501\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.111932\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.326670\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.227516\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.180158\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.063190\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.094183\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.199227\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.134326\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.196519\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.061267\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.207457\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.180878\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.167833\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.230542\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.056858\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.277348\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.346420\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.284692\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.078764\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.276666\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.098079\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.160414\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.123568\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.090984\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.281637\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.314111\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.119326\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.177320\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.094633\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.164699\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.182512\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.067990\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.100880\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.211275\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.163327\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.112168\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.250667\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.115639\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.138587\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.174949\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.311207\n",
      "\n",
      "Test set: Average loss: 0.1291, Accuracy: 9618/10000 (96%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.072746\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.101931\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.109316\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.235790\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.101290\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.183047\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.074685\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.077993\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.051053\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.180140\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.176921\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.202113\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.157352\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.113797\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.167872\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.125099\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.094302\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.211879\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.283903\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.108377\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.157603\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.227060\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.085086\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.233064\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.044959\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.101304\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.060911\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.039361\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.141903\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.095385\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.137817\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.035469\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.062758\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.057875\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.089899\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.160729\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.089852\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.103350\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.140786\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.266424\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.101202\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.103706\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.313007\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.147160\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.036242\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.222502\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.085723\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.138679\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.110198\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.112364\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.122795\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.137287\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.036638\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.030333\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.033024\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.142013\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.121550\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.094391\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.089772\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.070495\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.290220\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.048127\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.069664\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.161777\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.083441\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.062444\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.076078\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.141052\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.057858\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.071981\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.145721\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.184204\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.159254\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.139122\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.078775\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.095812\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.205378\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.036839\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.039359\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.109496\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.162019\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.114647\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.043775\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.168748\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.085545\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.058772\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.038790\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.147430\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.249254\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.168632\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.048621\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.150672\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.123705\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.080122\n",
      "\n",
      "Test set: Average loss: 0.1081, Accuracy: 9691/10000 (97%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.177892\n",
      "Train Epoch: 4 [640/60000 (1%)]\tLoss: 0.071717\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 0.112212\n",
      "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 0.108881\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 0.107863\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 0.070762\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 0.085716\n",
      "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 0.161057\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 0.041154\n",
      "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 0.059636\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.064056\n",
      "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 0.042855\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 0.050790\n",
      "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 0.049351\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 0.046565\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 0.101695\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 0.106453\n",
      "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 0.160861\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 0.090856\n",
      "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 0.238633\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.095251\n",
      "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 0.039365\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 0.085351\n",
      "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 0.131068\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 0.077947\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.057036\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 0.121683\n",
      "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 0.174756\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 0.158190\n",
      "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 0.025967\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.107554\n",
      "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 0.143004\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 0.083096\n",
      "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 0.017560\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 0.140431\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 0.150310\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 0.096578\n",
      "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 0.074929\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 0.077644\n",
      "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 0.160736\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.261824\n",
      "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 0.131393\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 0.103708\n",
      "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 0.079574\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 0.424193\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 0.077477\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 0.069166\n",
      "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 0.156541\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 0.154727\n",
      "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 0.225876\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.072495\n",
      "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 0.153285\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 0.018499\n",
      "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 0.126553\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 0.122591\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 0.099340\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 0.078403\n",
      "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 0.095136\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 0.073586\n",
      "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 0.204898\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.148136\n",
      "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 0.054364\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 0.158377\n",
      "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 0.084662\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 0.098881\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 0.046904\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 0.159832\n",
      "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 0.154094\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 0.070712\n",
      "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 0.057569\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.081919\n",
      "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 0.031475\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 0.050885\n",
      "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 0.100147\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 0.043457\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.089360\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 0.041097\n",
      "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 0.060520\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 0.063235\n",
      "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 0.151062\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.221754\n",
      "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 0.096518\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 0.066726\n",
      "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 0.087438\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 0.084667\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 0.064459\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 0.066549\n",
      "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 0.088997\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 0.156192\n",
      "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 0.061099\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.074302\n",
      "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 0.117866\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 0.080363\n",
      "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 0.159331\n",
      "\n",
      "Test set: Average loss: 0.0857, Accuracy: 9740/10000 (97%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.094925\n",
      "Train Epoch: 5 [640/60000 (1%)]\tLoss: 0.125394\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 0.019097\n",
      "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 0.046971\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 0.051490\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 0.135784\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 0.028836\n",
      "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 0.110547\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 0.052169\n",
      "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 0.285808\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.087713\n",
      "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 0.230167\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 0.202575\n",
      "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 0.147668\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 0.035988\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 0.163835\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 0.099947\n",
      "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 0.042383\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 0.046448\n",
      "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 0.140675\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.165210\n",
      "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 0.051692\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 0.066044\n",
      "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 0.220807\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 0.145730\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.089570\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 0.109320\n",
      "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 0.056481\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 0.180199\n",
      "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 0.066220\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.100829\n",
      "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 0.065404\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 0.150844\n",
      "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 0.266065\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 0.042036\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 0.133534\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 0.021697\n",
      "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 0.076451\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 0.059671\n",
      "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 0.272624\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.084065\n",
      "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 0.139459\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 0.098055\n",
      "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 0.147983\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 0.095322\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 0.060881\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 0.034975\n",
      "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 0.045707\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 0.011153\n",
      "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 0.049081\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.091135\n",
      "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 0.210655\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 0.099344\n",
      "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 0.102371\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 0.055940\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 0.112336\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 0.111958\n",
      "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 0.043142\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 0.087147\n",
      "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 0.073973\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.023437\n",
      "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 0.144262\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 0.212520\n",
      "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 0.045507\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 0.006637\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 0.197608\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 0.046362\n",
      "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 0.085498\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 0.100710\n",
      "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 0.179725\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.078818\n",
      "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 0.065995\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 0.113583\n",
      "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 0.049331\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 0.047678\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.058893\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 0.098023\n",
      "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 0.063500\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 0.250842\n",
      "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 0.090949\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.077464\n",
      "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 0.143852\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 0.062512\n",
      "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 0.058566\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 0.143215\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 0.035682\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 0.081905\n",
      "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 0.182609\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 0.074323\n",
      "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 0.009348\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.201175\n",
      "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 0.041289\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 0.102720\n",
      "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 0.041645\n",
      "\n",
      "Test set: Average loss: 0.0904, Accuracy: 9719/10000 (97%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.202864\n",
      "Train Epoch: 6 [640/60000 (1%)]\tLoss: 0.028306\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: 0.027710\n",
      "Train Epoch: 6 [1920/60000 (3%)]\tLoss: 0.117697\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 0.026214\n",
      "Train Epoch: 6 [3200/60000 (5%)]\tLoss: 0.033599\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: 0.114767\n",
      "Train Epoch: 6 [4480/60000 (7%)]\tLoss: 0.177061\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 0.080721\n",
      "Train Epoch: 6 [5760/60000 (10%)]\tLoss: 0.044406\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.060810\n",
      "Train Epoch: 6 [7040/60000 (12%)]\tLoss: 0.055022\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 0.154480\n",
      "Train Epoch: 6 [8320/60000 (14%)]\tLoss: 0.083311\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: 0.131416\n",
      "Train Epoch: 6 [9600/60000 (16%)]\tLoss: 0.035015\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 0.061888\n",
      "Train Epoch: 6 [10880/60000 (18%)]\tLoss: 0.043487\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: 0.006979\n",
      "Train Epoch: 6 [12160/60000 (20%)]\tLoss: 0.108600\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.022823\n",
      "Train Epoch: 6 [13440/60000 (22%)]\tLoss: 0.044105\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: 0.050567\n",
      "Train Epoch: 6 [14720/60000 (25%)]\tLoss: 0.210961\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 0.102896\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.063616\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: 0.131773\n",
      "Train Epoch: 6 [17280/60000 (29%)]\tLoss: 0.125684\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 0.234294\n",
      "Train Epoch: 6 [18560/60000 (31%)]\tLoss: 0.077750\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.229585\n",
      "Train Epoch: 6 [19840/60000 (33%)]\tLoss: 0.057958\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 0.007932\n",
      "Train Epoch: 6 [21120/60000 (35%)]\tLoss: 0.432708\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: 0.063470\n",
      "Train Epoch: 6 [22400/60000 (37%)]\tLoss: 0.135578\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 0.053634\n",
      "Train Epoch: 6 [23680/60000 (39%)]\tLoss: 0.086902\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: 0.114424\n",
      "Train Epoch: 6 [24960/60000 (42%)]\tLoss: 0.101790\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.150517\n",
      "Train Epoch: 6 [26240/60000 (44%)]\tLoss: 0.092004\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: 0.093829\n",
      "Train Epoch: 6 [27520/60000 (46%)]\tLoss: 0.143848\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 0.018454\n",
      "Train Epoch: 6 [28800/60000 (48%)]\tLoss: 0.070082\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: 0.075380\n",
      "Train Epoch: 6 [30080/60000 (50%)]\tLoss: 0.025584\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 0.147205\n",
      "Train Epoch: 6 [31360/60000 (52%)]\tLoss: 0.098022\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.033105\n",
      "Train Epoch: 6 [32640/60000 (54%)]\tLoss: 0.080500\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 0.040185\n",
      "Train Epoch: 6 [33920/60000 (57%)]\tLoss: 0.070718\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: 0.083218\n",
      "Train Epoch: 6 [35200/60000 (59%)]\tLoss: 0.156561\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 0.029440\n",
      "Train Epoch: 6 [36480/60000 (61%)]\tLoss: 0.159597\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: 0.064702\n",
      "Train Epoch: 6 [37760/60000 (63%)]\tLoss: 0.022367\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.068017\n",
      "Train Epoch: 6 [39040/60000 (65%)]\tLoss: 0.015467\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: 0.026782\n",
      "Train Epoch: 6 [40320/60000 (67%)]\tLoss: 0.060294\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 0.061537\n",
      "Train Epoch: 6 [41600/60000 (69%)]\tLoss: 0.028065\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: 0.038320\n",
      "Train Epoch: 6 [42880/60000 (71%)]\tLoss: 0.065343\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 0.159199\n",
      "Train Epoch: 6 [44160/60000 (74%)]\tLoss: 0.106454\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.042554\n",
      "Train Epoch: 6 [45440/60000 (76%)]\tLoss: 0.073988\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 0.029292\n",
      "Train Epoch: 6 [46720/60000 (78%)]\tLoss: 0.136242\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: 0.050045\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.057366\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 0.176180\n",
      "Train Epoch: 6 [49280/60000 (82%)]\tLoss: 0.019850\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: 0.052099\n",
      "Train Epoch: 6 [50560/60000 (84%)]\tLoss: 0.041417\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.061638\n",
      "Train Epoch: 6 [51840/60000 (86%)]\tLoss: 0.190609\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: 0.201530\n",
      "Train Epoch: 6 [53120/60000 (88%)]\tLoss: 0.062334\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 0.029951\n",
      "Train Epoch: 6 [54400/60000 (91%)]\tLoss: 0.055864\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: 0.032975\n",
      "Train Epoch: 6 [55680/60000 (93%)]\tLoss: 0.050653\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 0.056237\n",
      "Train Epoch: 6 [56960/60000 (95%)]\tLoss: 0.085877\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.050758\n",
      "Train Epoch: 6 [58240/60000 (97%)]\tLoss: 0.176562\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 0.085884\n",
      "Train Epoch: 6 [59520/60000 (99%)]\tLoss: 0.184165\n",
      "\n",
      "Test set: Average loss: 0.0860, Accuracy: 9727/10000 (97%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.050991\n",
      "Train Epoch: 7 [640/60000 (1%)]\tLoss: 0.071725\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: 0.095406\n",
      "Train Epoch: 7 [1920/60000 (3%)]\tLoss: 0.178320\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 0.147462\n",
      "Train Epoch: 7 [3200/60000 (5%)]\tLoss: 0.199174\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: 0.042562\n",
      "Train Epoch: 7 [4480/60000 (7%)]\tLoss: 0.057389\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 0.079412\n",
      "Train Epoch: 7 [5760/60000 (10%)]\tLoss: 0.024191\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.095178\n",
      "Train Epoch: 7 [7040/60000 (12%)]\tLoss: 0.092831\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 0.036783\n",
      "Train Epoch: 7 [8320/60000 (14%)]\tLoss: 0.099467\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: 0.060473\n",
      "Train Epoch: 7 [9600/60000 (16%)]\tLoss: 0.054459\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 0.131876\n",
      "Train Epoch: 7 [10880/60000 (18%)]\tLoss: 0.031465\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: 0.038172\n",
      "Train Epoch: 7 [12160/60000 (20%)]\tLoss: 0.334962\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.057218\n",
      "Train Epoch: 7 [13440/60000 (22%)]\tLoss: 0.062036\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: 0.078376\n",
      "Train Epoch: 7 [14720/60000 (25%)]\tLoss: 0.067538\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 0.055679\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.019979\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: 0.013323\n",
      "Train Epoch: 7 [17280/60000 (29%)]\tLoss: 0.051708\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 0.072806\n",
      "Train Epoch: 7 [18560/60000 (31%)]\tLoss: 0.116521\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.011185\n",
      "Train Epoch: 7 [19840/60000 (33%)]\tLoss: 0.031212\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 0.185392\n",
      "Train Epoch: 7 [21120/60000 (35%)]\tLoss: 0.084705\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: 0.010747\n",
      "Train Epoch: 7 [22400/60000 (37%)]\tLoss: 0.017464\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 0.111988\n",
      "Train Epoch: 7 [23680/60000 (39%)]\tLoss: 0.010164\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: 0.050071\n",
      "Train Epoch: 7 [24960/60000 (42%)]\tLoss: 0.194360\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.062005\n",
      "Train Epoch: 7 [26240/60000 (44%)]\tLoss: 0.029322\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: 0.017001\n",
      "Train Epoch: 7 [27520/60000 (46%)]\tLoss: 0.030507\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 0.045756\n",
      "Train Epoch: 7 [28800/60000 (48%)]\tLoss: 0.181913\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: 0.157266\n",
      "Train Epoch: 7 [30080/60000 (50%)]\tLoss: 0.045228\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 0.095193\n",
      "Train Epoch: 7 [31360/60000 (52%)]\tLoss: 0.031748\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.040082\n",
      "Train Epoch: 7 [32640/60000 (54%)]\tLoss: 0.157119\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 0.027831\n",
      "Train Epoch: 7 [33920/60000 (57%)]\tLoss: 0.101590\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: 0.177471\n",
      "Train Epoch: 7 [35200/60000 (59%)]\tLoss: 0.051398\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 0.177816\n",
      "Train Epoch: 7 [36480/60000 (61%)]\tLoss: 0.031817\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: 0.300782\n",
      "Train Epoch: 7 [37760/60000 (63%)]\tLoss: 0.103158\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.084358\n",
      "Train Epoch: 7 [39040/60000 (65%)]\tLoss: 0.014836\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: 0.060762\n",
      "Train Epoch: 7 [40320/60000 (67%)]\tLoss: 0.056272\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 0.046550\n",
      "Train Epoch: 7 [41600/60000 (69%)]\tLoss: 0.136788\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: 0.109293\n",
      "Train Epoch: 7 [42880/60000 (71%)]\tLoss: 0.056318\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 0.038470\n",
      "Train Epoch: 7 [44160/60000 (74%)]\tLoss: 0.221580\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.131859\n",
      "Train Epoch: 7 [45440/60000 (76%)]\tLoss: 0.019874\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 0.109433\n",
      "Train Epoch: 7 [46720/60000 (78%)]\tLoss: 0.115817\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: 0.025738\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.085763\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 0.057378\n",
      "Train Epoch: 7 [49280/60000 (82%)]\tLoss: 0.181015\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: 0.222181\n",
      "Train Epoch: 7 [50560/60000 (84%)]\tLoss: 0.111685\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.221480\n",
      "Train Epoch: 7 [51840/60000 (86%)]\tLoss: 0.025450\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: 0.133255\n",
      "Train Epoch: 7 [53120/60000 (88%)]\tLoss: 0.064047\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 0.031431\n",
      "Train Epoch: 7 [54400/60000 (91%)]\tLoss: 0.136696\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: 0.035780\n",
      "Train Epoch: 7 [55680/60000 (93%)]\tLoss: 0.075994\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 0.166224\n",
      "Train Epoch: 7 [56960/60000 (95%)]\tLoss: 0.116977\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.021718\n",
      "Train Epoch: 7 [58240/60000 (97%)]\tLoss: 0.023378\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 0.029889\n",
      "Train Epoch: 7 [59520/60000 (99%)]\tLoss: 0.043794\n",
      "\n",
      "Test set: Average loss: 0.0715, Accuracy: 9764/10000 (98%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.033537\n",
      "Train Epoch: 8 [640/60000 (1%)]\tLoss: 0.028342\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: 0.088016\n",
      "Train Epoch: 8 [1920/60000 (3%)]\tLoss: 0.111365\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 0.027258\n",
      "Train Epoch: 8 [3200/60000 (5%)]\tLoss: 0.018296\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: 0.013598\n",
      "Train Epoch: 8 [4480/60000 (7%)]\tLoss: 0.025733\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 0.146632\n",
      "Train Epoch: 8 [5760/60000 (10%)]\tLoss: 0.045826\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.038543\n",
      "Train Epoch: 8 [7040/60000 (12%)]\tLoss: 0.075737\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 0.028884\n",
      "Train Epoch: 8 [8320/60000 (14%)]\tLoss: 0.065983\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: 0.036232\n",
      "Train Epoch: 8 [9600/60000 (16%)]\tLoss: 0.163152\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 0.129870\n",
      "Train Epoch: 8 [10880/60000 (18%)]\tLoss: 0.028386\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: 0.010761\n",
      "Train Epoch: 8 [12160/60000 (20%)]\tLoss: 0.121029\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.071692\n",
      "Train Epoch: 8 [13440/60000 (22%)]\tLoss: 0.074730\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: 0.048138\n",
      "Train Epoch: 8 [14720/60000 (25%)]\tLoss: 0.175544\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 0.009832\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.084833\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: 0.051478\n",
      "Train Epoch: 8 [17280/60000 (29%)]\tLoss: 0.025895\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 0.028536\n",
      "Train Epoch: 8 [18560/60000 (31%)]\tLoss: 0.139109\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.149835\n",
      "Train Epoch: 8 [19840/60000 (33%)]\tLoss: 0.027523\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 0.049998\n",
      "Train Epoch: 8 [21120/60000 (35%)]\tLoss: 0.107767\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: 0.268545\n",
      "Train Epoch: 8 [22400/60000 (37%)]\tLoss: 0.304571\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 0.029228\n",
      "Train Epoch: 8 [23680/60000 (39%)]\tLoss: 0.097002\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: 0.054041\n",
      "Train Epoch: 8 [24960/60000 (42%)]\tLoss: 0.111991\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.038383\n",
      "Train Epoch: 8 [26240/60000 (44%)]\tLoss: 0.045931\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: 0.012950\n",
      "Train Epoch: 8 [27520/60000 (46%)]\tLoss: 0.106926\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 0.127886\n",
      "Train Epoch: 8 [28800/60000 (48%)]\tLoss: 0.018207\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: 0.051021\n",
      "Train Epoch: 8 [30080/60000 (50%)]\tLoss: 0.048221\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 0.152204\n",
      "Train Epoch: 8 [31360/60000 (52%)]\tLoss: 0.018482\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.024473\n",
      "Train Epoch: 8 [32640/60000 (54%)]\tLoss: 0.097669\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 0.055949\n",
      "Train Epoch: 8 [33920/60000 (57%)]\tLoss: 0.042384\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: 0.185359\n",
      "Train Epoch: 8 [35200/60000 (59%)]\tLoss: 0.160308\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 0.030598\n",
      "Train Epoch: 8 [36480/60000 (61%)]\tLoss: 0.036010\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: 0.090308\n",
      "Train Epoch: 8 [37760/60000 (63%)]\tLoss: 0.055707\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.042633\n",
      "Train Epoch: 8 [39040/60000 (65%)]\tLoss: 0.016724\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: 0.037823\n",
      "Train Epoch: 8 [40320/60000 (67%)]\tLoss: 0.032148\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 0.115548\n",
      "Train Epoch: 8 [41600/60000 (69%)]\tLoss: 0.304816\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: 0.043048\n",
      "Train Epoch: 8 [42880/60000 (71%)]\tLoss: 0.159181\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 0.016381\n",
      "Train Epoch: 8 [44160/60000 (74%)]\tLoss: 0.168638\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.082676\n",
      "Train Epoch: 8 [45440/60000 (76%)]\tLoss: 0.008318\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 0.077875\n",
      "Train Epoch: 8 [46720/60000 (78%)]\tLoss: 0.055848\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: 0.056193\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.034367\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 0.070099\n",
      "Train Epoch: 8 [49280/60000 (82%)]\tLoss: 0.285629\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: 0.112712\n",
      "Train Epoch: 8 [50560/60000 (84%)]\tLoss: 0.108551\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.126828\n",
      "Train Epoch: 8 [51840/60000 (86%)]\tLoss: 0.050436\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: 0.215813\n",
      "Train Epoch: 8 [53120/60000 (88%)]\tLoss: 0.117808\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 0.132751\n",
      "Train Epoch: 8 [54400/60000 (91%)]\tLoss: 0.050005\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: 0.149566\n",
      "Train Epoch: 8 [55680/60000 (93%)]\tLoss: 0.077692\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 0.030930\n",
      "Train Epoch: 8 [56960/60000 (95%)]\tLoss: 0.057417\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.011945\n",
      "Train Epoch: 8 [58240/60000 (97%)]\tLoss: 0.107072\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 0.027560\n",
      "Train Epoch: 8 [59520/60000 (99%)]\tLoss: 0.040839\n",
      "\n",
      "Test set: Average loss: 0.0762, Accuracy: 9762/10000 (98%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.124733\n",
      "Train Epoch: 9 [640/60000 (1%)]\tLoss: 0.076174\n",
      "Train Epoch: 9 [1280/60000 (2%)]\tLoss: 0.109397\n",
      "Train Epoch: 9 [1920/60000 (3%)]\tLoss: 0.046689\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 0.107839\n",
      "Train Epoch: 9 [3200/60000 (5%)]\tLoss: 0.029975\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: 0.019165\n",
      "Train Epoch: 9 [4480/60000 (7%)]\tLoss: 0.086494\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 0.038669\n",
      "Train Epoch: 9 [5760/60000 (10%)]\tLoss: 0.048938\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.155309\n",
      "Train Epoch: 9 [7040/60000 (12%)]\tLoss: 0.022950\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 0.117476\n",
      "Train Epoch: 9 [8320/60000 (14%)]\tLoss: 0.122500\n",
      "Train Epoch: 9 [8960/60000 (15%)]\tLoss: 0.086078\n",
      "Train Epoch: 9 [9600/60000 (16%)]\tLoss: 0.073878\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 0.168618\n",
      "Train Epoch: 9 [10880/60000 (18%)]\tLoss: 0.022992\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: 0.074424\n",
      "Train Epoch: 9 [12160/60000 (20%)]\tLoss: 0.107514\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.096110\n",
      "Train Epoch: 9 [13440/60000 (22%)]\tLoss: 0.256276\n",
      "Train Epoch: 9 [14080/60000 (23%)]\tLoss: 0.011676\n",
      "Train Epoch: 9 [14720/60000 (25%)]\tLoss: 0.016006\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 0.078473\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.022246\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: 0.130193\n",
      "Train Epoch: 9 [17280/60000 (29%)]\tLoss: 0.035074\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 0.023824\n",
      "Train Epoch: 9 [18560/60000 (31%)]\tLoss: 0.012616\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.105699\n",
      "Train Epoch: 9 [19840/60000 (33%)]\tLoss: 0.041036\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 0.130390\n",
      "Train Epoch: 9 [21120/60000 (35%)]\tLoss: 0.072064\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: 0.034900\n",
      "Train Epoch: 9 [22400/60000 (37%)]\tLoss: 0.027024\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 0.012174\n",
      "Train Epoch: 9 [23680/60000 (39%)]\tLoss: 0.082249\n",
      "Train Epoch: 9 [24320/60000 (41%)]\tLoss: 0.081721\n",
      "Train Epoch: 9 [24960/60000 (42%)]\tLoss: 0.022181\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.029233\n",
      "Train Epoch: 9 [26240/60000 (44%)]\tLoss: 0.094621\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: 0.110439\n",
      "Train Epoch: 9 [27520/60000 (46%)]\tLoss: 0.031097\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 0.159881\n",
      "Train Epoch: 9 [28800/60000 (48%)]\tLoss: 0.015942\n",
      "Train Epoch: 9 [29440/60000 (49%)]\tLoss: 0.229970\n",
      "Train Epoch: 9 [30080/60000 (50%)]\tLoss: 0.029749\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 0.138894\n",
      "Train Epoch: 9 [31360/60000 (52%)]\tLoss: 0.031927\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.031716\n",
      "Train Epoch: 9 [32640/60000 (54%)]\tLoss: 0.049172\n",
      "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 0.184497\n",
      "Train Epoch: 9 [33920/60000 (57%)]\tLoss: 0.019275\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: 0.032394\n",
      "Train Epoch: 9 [35200/60000 (59%)]\tLoss: 0.062218\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 0.078348\n",
      "Train Epoch: 9 [36480/60000 (61%)]\tLoss: 0.039612\n",
      "Train Epoch: 9 [37120/60000 (62%)]\tLoss: 0.035562\n",
      "Train Epoch: 9 [37760/60000 (63%)]\tLoss: 0.090855\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.075093\n",
      "Train Epoch: 9 [39040/60000 (65%)]\tLoss: 0.089184\n",
      "Train Epoch: 9 [39680/60000 (66%)]\tLoss: 0.053044\n",
      "Train Epoch: 9 [40320/60000 (67%)]\tLoss: 0.031873\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 0.088367\n",
      "Train Epoch: 9 [41600/60000 (69%)]\tLoss: 0.030188\n",
      "Train Epoch: 9 [42240/60000 (70%)]\tLoss: 0.082014\n",
      "Train Epoch: 9 [42880/60000 (71%)]\tLoss: 0.130610\n",
      "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 0.076053\n",
      "Train Epoch: 9 [44160/60000 (74%)]\tLoss: 0.073227\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.057741\n",
      "Train Epoch: 9 [45440/60000 (76%)]\tLoss: 0.047318\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 0.048031\n",
      "Train Epoch: 9 [46720/60000 (78%)]\tLoss: 0.012949\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: 0.135328\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.126654\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 0.032999\n",
      "Train Epoch: 9 [49280/60000 (82%)]\tLoss: 0.084346\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: 0.094196\n",
      "Train Epoch: 9 [50560/60000 (84%)]\tLoss: 0.053034\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.086795\n",
      "Train Epoch: 9 [51840/60000 (86%)]\tLoss: 0.049845\n",
      "Train Epoch: 9 [52480/60000 (87%)]\tLoss: 0.241943\n",
      "Train Epoch: 9 [53120/60000 (88%)]\tLoss: 0.011407\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 0.058543\n",
      "Train Epoch: 9 [54400/60000 (91%)]\tLoss: 0.050478\n",
      "Train Epoch: 9 [55040/60000 (92%)]\tLoss: 0.125934\n",
      "Train Epoch: 9 [55680/60000 (93%)]\tLoss: 0.011471\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 0.052082\n",
      "Train Epoch: 9 [56960/60000 (95%)]\tLoss: 0.062144\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.079709\n",
      "Train Epoch: 9 [58240/60000 (97%)]\tLoss: 0.011557\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 0.031351\n",
      "Train Epoch: 9 [59520/60000 (99%)]\tLoss: 0.140749\n",
      "\n",
      "Test set: Average loss: 0.0680, Accuracy: 9782/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# https://github.com/pytorch/examples/blob/master/mnist/main.py\n",
    "#*******************************************************************************\n",
    "#Purpose: Pytorch code for CNN accelerator using Verilog hdl\n",
    "#Revision History: 2023.03.03\n",
    "#*******************************************************************************\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 64\n",
    "train_dataset = datasets.MNIST(root='./data/',\n",
    "                                train=True,\n",
    "                                transform=transforms.ToTensor(),\n",
    "                                download=True)\n",
    "test_dataset = datasets.MNIST(root='./data/',\n",
    "                                train=False,\n",
    "                                transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=False)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv1_out_np = np.zeros((1, 4, 24, 24))\n",
    "        self.mp1_out_np = np.zeros((1, 4, 12, 12))\n",
    "        self.conv2_out_np = np.zeros((1, 12, 8, 8))\n",
    "        self.mp2_out_np = np.zeros((1, 12, 4, 4))\n",
    "        self.fc_in_np = np.zeros((1, 192))\n",
    "        self.fc_out_np = np.zeros((1, 10))\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 4, kernel_size=5, bias=False) \n",
    "        self.conv2 = nn.Conv2d(4, 12, kernel_size=5, bias=False)\n",
    "        self.mp = nn.MaxPool2d(2)\n",
    "        self.fc_1 = nn.Linear(192, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "        x = self.conv1(x)\n",
    "        self.conv1_out_np = x.detach().numpy()\n",
    "        x = F.relu(self.mp(x))\n",
    "        self.mp1_out_np = x.detach().numpy()\n",
    "        x = self.conv2(x)\n",
    "        self.conv2_out_np = x.detach().numpy()\n",
    "        x = F.relu(self.mp(x))\n",
    "        self.mp2_out_np = x.detach().numpy()\n",
    "        x = x.view(in_size, -1) \n",
    "        self.fc_in_np = x.detach().numpy()\n",
    "        x = self.fc_1(x)\n",
    "        self.fc_out_np = x.detach().numpy()\n",
    "        return F.log_softmax(x)\n",
    "     \n",
    "model = Net()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    \n",
    "    for data, target in test_loader:\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "        pred = output.data.max(1, keepdim=True)[1] \n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "for epoch in range(1, 10):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert .jpg file to .txt file\n",
    "from PIL import Image\n",
    "#from fxpmath import Fxp\n",
    "\n",
    "    \n",
    "def convert_img_to_txt():\n",
    "    image_location = \"C:\\\\Users\\\\newb\\\\Desktop\\\\MNIST_test_image\\\\9\\\\img\"\n",
    "    image_extension = \".jpg\"\n",
    "    image_data = []\n",
    "    for i in range(1, 1001):\n",
    "        img_path = f\"{image_location}{i}{image_extension}\"\n",
    "        img = Image.open(img_path, \"r\")\n",
    "        np_img = np.array(img)\n",
    "        np_img_re = np.reshape(np_img,(28,28))\n",
    "        image_data.append(np_img_re)\n",
    "        img.close()\n",
    "    \n",
    "    stacked_data = np.vstack(image_data)\n",
    "    np.savetxt('test_num9.txt', stacked_data, fmt='%d',delimiter = \" \")\n",
    "   \n",
    "    \n",
    "convert_img_to_txt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Conv1 ############\n",
    "import numpy as np\n",
    "int_conv1_weight_1 =  torch.tensor((model.conv1.weight.data[0][0] * 128), dtype = torch.int32)\n",
    "int_conv1_weight_2 =  torch.tensor((model.conv1.weight.data[1][0] * 128), dtype = torch.int32)\n",
    "int_conv1_weight_3 =  torch.tensor((model.conv1.weight.data[2][0] * 128), dtype = torch.int32)\n",
    "int_conv1_weight_4 =  torch.tensor((model.conv1.weight.data[3][0] * 128), dtype = torch.int32)\n",
    "#It is to prevent overflow of weights. If the weight value exceeds 127 (011111111), MSB becomes 1 when it is converted into a Binary of 8bit.\n",
    "#However, in HW, this means negative. Therefore, the number exceeding 127 is fixed to 127.\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        if int_conv1_weight_1[i][j] > 127:\n",
    "            int_conv1_weight_1[i][j] = 127\n",
    "        if int_conv1_weight_2[i][j] > 127:\n",
    "            int_conv1_weight_2[i][j] = 127\n",
    "        if int_conv1_weight_3[i][j] > 127:\n",
    "            int_conv1_weight_3[i][j] = 127\n",
    "        if int_conv1_weight_4[i][j] > 127:\n",
    "            int_conv1_weight_4[i][j] = 127\n",
    "int_conv1_weight_stack = np.vstack((int_conv1_weight_1,int_conv1_weight_2,int_conv1_weight_3,int_conv1_weight_4))\n",
    "print(\"Signed\")\n",
    "print(int_conv1_weight_stack)\n",
    "print(int_conv1_weight_1)\n",
    "print(int_conv1_weight_2)\n",
    "print(int_conv1_weight_3)\n",
    "print(int_conv1_weight_4)\n",
    "np.savetxt('SW_conv1_weight.txt', int_conv1_weight_stack, fmt='%d',delimiter = \" \")\n",
    "\n",
    "# If the value of the weight is negative, then +256 based on 8 bits and extract it as the Hex value, HW accepts it as the correct negative value.\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        if int_conv1_weight_1[i][j] < 0:\n",
    "            int_conv1_weight_1[i][j] += 256\n",
    "        if int_conv1_weight_2[i][j] < 0:\n",
    "            int_conv1_weight_2[i][j] += 256\n",
    "        if int_conv1_weight_3[i][j] < 0:\n",
    "            int_conv1_weight_3[i][j] += 256\n",
    "        if int_conv1_weight_4[i][j] < 0:\n",
    "            int_conv1_weight_4[i][j] += 256\n",
    "\n",
    "int_conv1_weight_stack = np.vstack((int_conv1_weight_1,int_conv1_weight_2,int_conv1_weight_3,int_conv1_weight_4))\n",
    "print (\"Unsigned\")\n",
    "print(int_conv1_weight_stack)\n",
    "print(int_conv1_weight_1)\n",
    "print(int_conv1_weight_2)\n",
    "print(int_conv1_weight_3)\n",
    "print(int_conv1_weight_4)\n",
    "np.savetxt('HW_conv1_weight.mem', int_conv1_weight_stack, fmt='%1.2X',delimiter = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############## Conv2 ############\n",
    "import numpy as np\n",
    "print(np.shape(model.conv2.weight))\n",
    "\n",
    "int_conv2_weight_11 =  torch.tensor((model.conv2.weight.data[0][0]* 128), dtype = torch.int32)\n",
    "int_conv2_weight_12 =  torch.tensor((model.conv2.weight.data[0][1]* 128), dtype = torch.int32)\n",
    "int_conv2_weight_13 =  torch.tensor((model.conv2.weight.data[0][2]* 128), dtype = torch.int32)\n",
    "int_conv2_weight_14 =  torch.tensor((model.conv2.weight.data[0][3]* 128), dtype = torch.int32)\n",
    "\n",
    "int_conv2_weight_21 =  torch.tensor((model.conv2.weight.data[1][0] * 128), dtype = torch.int32)\n",
    "int_conv2_weight_22 =  torch.tensor((model.conv2.weight.data[1][1] * 128), dtype = torch.int32)\n",
    "int_conv2_weight_23 =  torch.tensor((model.conv2.weight.data[1][2] * 128), dtype = torch.int32)\n",
    "int_conv2_weight_24 =  torch.tensor((model.conv2.weight.data[1][3] * 128), dtype = torch.int32)\n",
    "\n",
    "int_conv2_weight_31 =  torch.tensor((model.conv2.weight.data[2][0] * 128), dtype = torch.int32)\n",
    "int_conv2_weight_32 =  torch.tensor((model.conv2.weight.data[2][1] * 128), dtype = torch.int32)\n",
    "int_conv2_weight_33 =  torch.tensor((model.conv2.weight.data[2][2] * 128), dtype = torch.int32)\n",
    "int_conv2_weight_34 =  torch.tensor((model.conv2.weight.data[2][3] * 128), dtype = torch.int32)\n",
    "\n",
    "int_conv2_weight_41 =  torch.tensor((model.conv2.weight.data[3][0] * 128), dtype = torch.int32)\n",
    "int_conv2_weight_42 =  torch.tensor((model.conv2.weight.data[3][1] * 128), dtype = torch.int32)\n",
    "int_conv2_weight_43 =  torch.tensor((model.conv2.weight.data[3][2] * 128), dtype = torch.int32)\n",
    "int_conv2_weight_44 =  torch.tensor((model.conv2.weight.data[3][3] * 128), dtype = torch.int32)\n",
    "\n",
    "int_conv2_weight_51 =  torch.tensor((model.conv2.weight.data[4][0] * 128), dtype = torch.int32)\n",
    "int_conv2_weight_52 =  torch.tensor((model.conv2.weight.data[4][1] * 128), dtype = torch.int32)\n",
    "int_conv2_weight_53 =  torch.tensor((model.conv2.weight.data[4][2] * 128), dtype = torch.int32)\n",
    "int_conv2_weight_54 =  torch.tensor((model.conv2.weight.data[4][3] * 128), dtype = torch.int32)\n",
    "\n",
    "int_conv2_weight_61 =  torch.tensor((model.conv2.weight.data[5][0] * 128), dtype = torch.int32)\n",
    "int_conv2_weight_62 =  torch.tensor((model.conv2.weight.data[5][1] * 128), dtype = torch.int32)\n",
    "int_conv2_weight_63 =  torch.tensor((model.conv2.weight.data[5][2] * 128), dtype = torch.int32)\n",
    "int_conv2_weight_64 =  torch.tensor((model.conv2.weight.data[5][3] * 128), dtype = torch.int32)\n",
    "\n",
    "int_conv2_weight_71 =  torch.tensor((model.conv2.weight.data[6][0] * 128), dtype = torch.int32)\n",
    "int_conv2_weight_72 =  torch.tensor((model.conv2.weight.data[6][1] * 128), dtype = torch.int32)\n",
    "int_conv2_weight_73 =  torch.tensor((model.conv2.weight.data[6][2] * 128), dtype = torch.int32)\n",
    "int_conv2_weight_74 =  torch.tensor((model.conv2.weight.data[6][3] * 128), dtype = torch.int32)\n",
    "\n",
    "int_conv2_weight_81 =  torch.tensor((model.conv2.weight.data[7][0] * 128), dtype = torch.int32)\n",
    "int_conv2_weight_82 =  torch.tensor((model.conv2.weight.data[7][1] * 128), dtype = torch.int32)\n",
    "int_conv2_weight_83 =  torch.tensor((model.conv2.weight.data[7][2] * 128), dtype = torch.int32)\n",
    "int_conv2_weight_84 =  torch.tensor((model.conv2.weight.data[7][3] * 128), dtype = torch.int32)\n",
    "\n",
    "int_conv2_weight_91 =  torch.tensor((model.conv2.weight.data[8][0] * 128), dtype = torch.int32)\n",
    "int_conv2_weight_92 =  torch.tensor((model.conv2.weight.data[8][1] * 128), dtype = torch.int32)\n",
    "int_conv2_weight_93 =  torch.tensor((model.conv2.weight.data[8][2] * 128), dtype = torch.int32)\n",
    "int_conv2_weight_94 =  torch.tensor((model.conv2.weight.data[8][3] * 128), dtype = torch.int32)\n",
    "\n",
    "int_conv2_weight_101 =  torch.tensor((model.conv2.weight.data[9][0] * 128), dtype = torch.int32)\n",
    "int_conv2_weight_102 =  torch.tensor((model.conv2.weight.data[9][1] * 128), dtype = torch.int32)\n",
    "int_conv2_weight_103 =  torch.tensor((model.conv2.weight.data[9][2] * 128), dtype = torch.int32)\n",
    "int_conv2_weight_104 =  torch.tensor((model.conv2.weight.data[9][3] * 128), dtype = torch.int32)\n",
    "\n",
    "int_conv2_weight_111 =  torch.tensor((model.conv2.weight.data[10][0] * 128), dtype = torch.int32)\n",
    "int_conv2_weight_112 =  torch.tensor((model.conv2.weight.data[10][1] * 128), dtype = torch.int32)\n",
    "int_conv2_weight_113 =  torch.tensor((model.conv2.weight.data[10][2] * 128), dtype = torch.int32)\n",
    "int_conv2_weight_114 =  torch.tensor((model.conv2.weight.data[10][3] * 128), dtype = torch.int32)\n",
    "\n",
    "int_conv2_weight_121 =  torch.tensor((model.conv2.weight.data[11][0] * 128), dtype = torch.int32)\n",
    "int_conv2_weight_122 =  torch.tensor((model.conv2.weight.data[11][1] * 128), dtype = torch.int32)\n",
    "int_conv2_weight_123 =  torch.tensor((model.conv2.weight.data[11][2] * 128), dtype = torch.int32)\n",
    "int_conv2_weight_124 =  torch.tensor((model.conv2.weight.data[11][3] * 128), dtype = torch.int32)\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        if int_conv2_weight_11[i][j] > 127:\n",
    "            int_conv2_weight_11[i][j] = 127\n",
    "        if int_conv2_weight_12[i][j] > 127:\n",
    "            int_conv2_weight_12[i][j] = 127\n",
    "        if int_conv2_weight_13[i][j] > 127:\n",
    "            int_conv2_weight_13[i][j] = 127\n",
    "        if int_conv2_weight_14[i][j] > 127:\n",
    "            int_conv2_weight_14[i][j] = 127\n",
    "            \n",
    "        if int_conv2_weight_21[i][j] > 127:\n",
    "            int_conv2_weight_21[i][j] = 127\n",
    "        if int_conv2_weight_22[i][j] > 127:\n",
    "            int_conv2_weight_22[i][j] = 127\n",
    "        if int_conv2_weight_23[i][j] > 127:\n",
    "            int_conv2_weight_23[i][j] = 127\n",
    "        if int_conv2_weight_24[i][j] > 127:\n",
    "            int_conv2_weight_24[i][j] = 127   \n",
    "             \n",
    "        if int_conv2_weight_31[i][j] > 127:\n",
    "            int_conv2_weight_31[i][j] = 127\n",
    "        if int_conv2_weight_32[i][j] > 127:\n",
    "            int_conv2_weight_32[i][j] = 127\n",
    "        if int_conv2_weight_33[i][j] > 127:\n",
    "            int_conv2_weight_33[i][j] = 127\n",
    "        if int_conv2_weight_34[i][j] > 127:\n",
    "            int_conv2_weight_34[i][j] = 127   \n",
    "        \n",
    "        if int_conv2_weight_41[i][j] > 127:\n",
    "            int_conv2_weight_41[i][j] = 127\n",
    "        if int_conv2_weight_42[i][j] > 127:\n",
    "            int_conv2_weight_42[i][j] = 127\n",
    "        if int_conv2_weight_43[i][j] > 127:\n",
    "            int_conv2_weight_43[i][j] = 127\n",
    "        if int_conv2_weight_44[i][j] > 127:\n",
    "            int_conv2_weight_44[i][j] = 127\n",
    "            \n",
    "        if int_conv2_weight_51[i][j] > 127:\n",
    "            int_conv2_weight_51[i][j] = 127\n",
    "        if int_conv2_weight_52[i][j] > 127:\n",
    "            int_conv2_weight_52[i][j] = 127\n",
    "        if int_conv2_weight_53[i][j] > 127:\n",
    "            int_conv2_weight_53[i][j] = 127\n",
    "        if int_conv2_weight_54[i][j] > 127:\n",
    "            int_conv2_weight_54[i][j] = 127   \n",
    "             \n",
    "        if int_conv2_weight_61[i][j] > 127:\n",
    "            int_conv2_weight_61[i][j] = 127\n",
    "        if int_conv2_weight_62[i][j] > 127:\n",
    "            int_conv2_weight_62[i][j] = 127\n",
    "        if int_conv2_weight_63[i][j] > 127:\n",
    "            int_conv2_weight_63[i][j] = 127\n",
    "        if int_conv2_weight_64[i][j] > 127:\n",
    "            int_conv2_weight_64[i][j] = 127\n",
    "        \n",
    "        if int_conv2_weight_71[i][j] > 127:\n",
    "            int_conv2_weight_71[i][j] = 127\n",
    "        if int_conv2_weight_72[i][j] > 127:\n",
    "            int_conv2_weight_72[i][j] = 127\n",
    "        if int_conv2_weight_73[i][j] > 127:\n",
    "            int_conv2_weight_73[i][j] = 127\n",
    "        if int_conv2_weight_74[i][j] > 127:\n",
    "            int_conv2_weight_74[i][j] = 127\n",
    "            \n",
    "        if int_conv2_weight_81[i][j] > 127:\n",
    "            int_conv2_weight_81[i][j] = 127\n",
    "        if int_conv2_weight_82[i][j] > 127:\n",
    "            int_conv2_weight_82[i][j] = 127\n",
    "        if int_conv2_weight_83[i][j] > 127:\n",
    "            int_conv2_weight_83[i][j] = 127\n",
    "        if int_conv2_weight_84[i][j] > 127:\n",
    "            int_conv2_weight_84[i][j] = 127   \n",
    "             \n",
    "        if int_conv2_weight_91[i][j] > 127:\n",
    "            int_conv2_weight_91[i][j] = 127\n",
    "        if int_conv2_weight_92[i][j] > 127:\n",
    "            int_conv2_weight_92[i][j] = 127\n",
    "        if int_conv2_weight_93[i][j] > 127:\n",
    "            int_conv2_weight_93[i][j] = 127\n",
    "        if int_conv2_weight_94[i][j] > 127:\n",
    "            int_conv2_weight_94[i][j] = 127  \n",
    "        \n",
    "        if int_conv2_weight_101[i][j] > 127:\n",
    "            int_conv2_weight_101[i][j] = 127\n",
    "        if int_conv2_weight_102[i][j] > 127:\n",
    "            int_conv2_weight_102[i][j] = 127\n",
    "        if int_conv2_weight_103[i][j] > 127:\n",
    "            int_conv2_weight_103[i][j] = 127\n",
    "        if int_conv2_weight_104[i][j] > 127:\n",
    "            int_conv2_weight_104[i][j] = 127\n",
    "            \n",
    "        if int_conv2_weight_111[i][j] > 127:\n",
    "            int_conv2_weight_111[i][j] = 127\n",
    "        if int_conv2_weight_112[i][j] > 127:\n",
    "            int_conv2_weight_112[i][j] = 127\n",
    "        if int_conv2_weight_113[i][j] > 127:\n",
    "            int_conv2_weight_113[i][j] = 127\n",
    "        if int_conv2_weight_114[i][j] > 127:\n",
    "            int_conv2_weight_114[i][j] = 127 \n",
    "             \n",
    "        if int_conv2_weight_121[i][j] > 127:\n",
    "            int_conv2_weight_121[i][j] = 127\n",
    "        if int_conv2_weight_122[i][j] > 127:\n",
    "            int_conv2_weight_122[i][j] = 127\n",
    "        if int_conv2_weight_123[i][j] > 127:\n",
    "            int_conv2_weight_123[i][j] = 127\n",
    "        if int_conv2_weight_124[i][j] > 127:\n",
    "            int_conv2_weight_124[i][j] = 127\n",
    "            \n",
    "int_conv2_weight_stack = np.vstack((int_conv2_weight_11,int_conv2_weight_21,int_conv2_weight_31,int_conv2_weight_41,int_conv2_weight_51,int_conv2_weight_61,\n",
    "                                        int_conv2_weight_71,int_conv2_weight_81,int_conv2_weight_91,int_conv2_weight_101,int_conv2_weight_111,int_conv2_weight_121,\n",
    "                                        int_conv2_weight_12,int_conv2_weight_22,int_conv2_weight_32,int_conv2_weight_42,int_conv2_weight_52,int_conv2_weight_62,\n",
    "                                        int_conv2_weight_72,int_conv2_weight_82,int_conv2_weight_92,int_conv2_weight_102,int_conv2_weight_112,int_conv2_weight_122,\n",
    "                                        int_conv2_weight_13,int_conv2_weight_23,int_conv2_weight_33,int_conv2_weight_43,int_conv2_weight_53,int_conv2_weight_63,\n",
    "                                        int_conv2_weight_73,int_conv2_weight_83,int_conv2_weight_93,int_conv2_weight_103,int_conv2_weight_113,int_conv2_weight_123,\n",
    "                                        int_conv2_weight_14,int_conv2_weight_24,int_conv2_weight_34,int_conv2_weight_44,int_conv2_weight_54,int_conv2_weight_64,\n",
    "                                        int_conv2_weight_74,int_conv2_weight_84,int_conv2_weight_94,int_conv2_weight_104,int_conv2_weight_114,int_conv2_weight_124))\n",
    "\n",
    "print (\"Signed\")\n",
    "print(int_conv2_weight_stack, '\\n')\n",
    "np.savetxt('SW_conv2_weight.txt', int_conv2_weight_stack, fmt='%d',delimiter = \" \")\n",
    "\n",
    "# signed int => unsigned int\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        if int_conv2_weight_11[i][j] < 0:\n",
    "            int_conv2_weight_11[i][j] += 256\n",
    "        if int_conv2_weight_12[i][j] < 0:\n",
    "            int_conv2_weight_12[i][j] += 256\n",
    "        if int_conv2_weight_13[i][j] < 0:\n",
    "            int_conv2_weight_13[i][j] += 256\n",
    "        if int_conv2_weight_14[i][j] < 0:\n",
    "            int_conv2_weight_14[i][j] += 256\n",
    "            \n",
    "        if int_conv2_weight_21[i][j] < 0:\n",
    "            int_conv2_weight_21[i][j] += 256\n",
    "        if int_conv2_weight_22[i][j] < 0:\n",
    "            int_conv2_weight_22[i][j] += 256\n",
    "        if int_conv2_weight_23[i][j] < 0:\n",
    "            int_conv2_weight_23[i][j] += 256\n",
    "        if int_conv2_weight_24[i][j] < 0:\n",
    "            int_conv2_weight_24[i][j] += 256   \n",
    "             \n",
    "        if int_conv2_weight_31[i][j] < 0:\n",
    "            int_conv2_weight_31[i][j] += 256\n",
    "        if int_conv2_weight_32[i][j] < 0:\n",
    "            int_conv2_weight_32[i][j] += 256\n",
    "        if int_conv2_weight_33[i][j] < 0:\n",
    "            int_conv2_weight_33[i][j] += 256\n",
    "        if int_conv2_weight_34[i][j] < 0:\n",
    "            int_conv2_weight_34[i][j] += 256   \n",
    "        \n",
    "        if int_conv2_weight_41[i][j] < 0:\n",
    "            int_conv2_weight_41[i][j] += 256\n",
    "        if int_conv2_weight_42[i][j] < 0:\n",
    "            int_conv2_weight_42[i][j] += 256\n",
    "        if int_conv2_weight_43[i][j] < 0:\n",
    "            int_conv2_weight_43[i][j] += 256\n",
    "        if int_conv2_weight_44[i][j] < 0:\n",
    "            int_conv2_weight_44[i][j] += 256\n",
    "            \n",
    "        if int_conv2_weight_51[i][j] < 0:\n",
    "            int_conv2_weight_51[i][j] += 256\n",
    "        if int_conv2_weight_52[i][j] < 0:\n",
    "            int_conv2_weight_52[i][j] += 256\n",
    "        if int_conv2_weight_53[i][j] < 0:\n",
    "            int_conv2_weight_53[i][j] += 256\n",
    "        if int_conv2_weight_54[i][j] < 0:\n",
    "            int_conv2_weight_54[i][j] += 256   \n",
    "             \n",
    "        if int_conv2_weight_61[i][j] < 0:\n",
    "            int_conv2_weight_61[i][j] += 256\n",
    "        if int_conv2_weight_62[i][j] < 0:\n",
    "            int_conv2_weight_62[i][j] += 256\n",
    "        if int_conv2_weight_63[i][j] < 0:\n",
    "            int_conv2_weight_63[i][j] += 256\n",
    "        if int_conv2_weight_64[i][j] < 0:\n",
    "            int_conv2_weight_64[i][j] += 256\n",
    "        \n",
    "        if int_conv2_weight_71[i][j] < 0:\n",
    "            int_conv2_weight_71[i][j] += 256\n",
    "        if int_conv2_weight_72[i][j] < 0:\n",
    "            int_conv2_weight_72[i][j] += 256\n",
    "        if int_conv2_weight_73[i][j] < 0:\n",
    "            int_conv2_weight_73[i][j] += 256\n",
    "        if int_conv2_weight_74[i][j] < 0:\n",
    "            int_conv2_weight_74[i][j] += 256\n",
    "            \n",
    "        if int_conv2_weight_81[i][j] < 0:\n",
    "            int_conv2_weight_81[i][j] += 256\n",
    "        if int_conv2_weight_82[i][j] < 0:\n",
    "            int_conv2_weight_82[i][j] += 256\n",
    "        if int_conv2_weight_83[i][j] < 0:\n",
    "            int_conv2_weight_83[i][j] += 256\n",
    "        if int_conv2_weight_84[i][j] < 0:\n",
    "            int_conv2_weight_84[i][j] += 256   \n",
    "             \n",
    "        if int_conv2_weight_91[i][j] < 0:\n",
    "            int_conv2_weight_91[i][j] += 256\n",
    "        if int_conv2_weight_92[i][j] < 0:\n",
    "            int_conv2_weight_92[i][j] += 256\n",
    "        if int_conv2_weight_93[i][j] < 0:\n",
    "            int_conv2_weight_93[i][j] += 256\n",
    "        if int_conv2_weight_94[i][j] < 0:\n",
    "            int_conv2_weight_94[i][j] += 256   \n",
    "        \n",
    "        if int_conv2_weight_101[i][j] < 0:\n",
    "            int_conv2_weight_101[i][j] += 256\n",
    "        if int_conv2_weight_102[i][j] < 0:\n",
    "            int_conv2_weight_102[i][j] += 256\n",
    "        if int_conv2_weight_103[i][j] < 0:\n",
    "            int_conv2_weight_103[i][j] += 256\n",
    "        if int_conv2_weight_104[i][j] < 0:\n",
    "            int_conv2_weight_104[i][j] += 256\n",
    "            \n",
    "        if int_conv2_weight_111[i][j] < 0:\n",
    "            int_conv2_weight_111[i][j] += 256\n",
    "        if int_conv2_weight_112[i][j] < 0:\n",
    "            int_conv2_weight_112[i][j] += 256\n",
    "        if int_conv2_weight_113[i][j] < 0:\n",
    "            int_conv2_weight_113[i][j] += 256\n",
    "        if int_conv2_weight_114[i][j] < 0:\n",
    "            int_conv2_weight_114[i][j] += 256   \n",
    "             \n",
    "        if int_conv2_weight_121[i][j] < 0:\n",
    "            int_conv2_weight_121[i][j] += 256\n",
    "        if int_conv2_weight_122[i][j] < 0:\n",
    "            int_conv2_weight_122[i][j] += 256\n",
    "        if int_conv2_weight_123[i][j] < 0:\n",
    "            int_conv2_weight_123[i][j] += 256\n",
    "        if int_conv2_weight_124[i][j] < 0:\n",
    "            int_conv2_weight_124[i][j] += 256   \n",
    "        \n",
    "\n",
    "int_conv2_weight_stack_ch1 = np.vstack((int_conv2_weight_11,int_conv2_weight_21,int_conv2_weight_31,int_conv2_weight_41,int_conv2_weight_51,int_conv2_weight_61,\n",
    "                                        int_conv2_weight_71,int_conv2_weight_81,int_conv2_weight_91,int_conv2_weight_101,int_conv2_weight_111,int_conv2_weight_121))\n",
    "int_conv2_weight_stack_ch2 = np.vstack((int_conv2_weight_12,int_conv2_weight_22,int_conv2_weight_32,int_conv2_weight_42,int_conv2_weight_52,int_conv2_weight_62,\n",
    "                                        int_conv2_weight_72,int_conv2_weight_82,int_conv2_weight_92,int_conv2_weight_102,int_conv2_weight_112,int_conv2_weight_122))\n",
    "int_conv2_weight_stack_ch3 = np.vstack((int_conv2_weight_13,int_conv2_weight_23,int_conv2_weight_33,int_conv2_weight_43,int_conv2_weight_53,int_conv2_weight_63,\n",
    "                                        int_conv2_weight_73,int_conv2_weight_83,int_conv2_weight_93,int_conv2_weight_103,int_conv2_weight_113,int_conv2_weight_123))\n",
    "int_conv2_weight_stack_ch4 = np.vstack((int_conv2_weight_14,int_conv2_weight_24,int_conv2_weight_34,int_conv2_weight_44,int_conv2_weight_54,int_conv2_weight_64,\n",
    "                                        int_conv2_weight_74,int_conv2_weight_84,int_conv2_weight_94,int_conv2_weight_104,int_conv2_weight_114,int_conv2_weight_124))\n",
    "\n",
    "print (\"Unsigned\")\n",
    "print(int_conv2_weight_stack_ch1, '\\n')\n",
    "print(int_conv2_weight_stack_ch2, '\\n')\n",
    "print(int_conv2_weight_stack_ch3, '\\n')\n",
    "print(int_conv2_weight_stack_ch4, '\\n')\n",
    "\n",
    "np.savetxt('HW_conv2_weight_ch1.mem', int_conv2_weight_stack_ch1, fmt='%1.2X',delimiter = \" \")\n",
    "np.savetxt('HW_conv2_weight_ch2.mem', int_conv2_weight_stack_ch2, fmt='%1.2X',delimiter = \" \")\n",
    "np.savetxt('HW_conv2_weight_ch3.mem', int_conv2_weight_stack_ch3, fmt='%1.2X',delimiter = \" \")\n",
    "np.savetxt('HW_conv2_weight_ch4.mem', int_conv2_weight_stack_ch4, fmt='%1.2X',delimiter = \" \")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## FC Layer ############\n",
    "\n",
    "print(np.shape(model.fc_1.weight))\n",
    "print((model.fc_1.weight * 128).int())\n",
    "\n",
    "print(np.shape(model.fc_1.bias))\n",
    "print((model.fc_1.bias * 128 * 256).int())\n",
    "\n",
    "int_fc_weight = (model.fc_1.weight * 128).int()\n",
    "int_fc_bias = (model.fc_1.bias * 128 * 256).int() #16bit bias\n",
    "for i in range(10):\n",
    "    for j in range(192):\n",
    "        if int_fc_weight[i][j] > 127 :\n",
    "            int_fc_weight[i][j] = 127\n",
    "            \n",
    "np.savetxt('SW_fc_weight.txt', int_fc_weight, fmt='%d',delimiter = \" \")\n",
    "np.savetxt('SW_fc_bias.txt', int_fc_bias, fmt='%d',delimiter = \" \")\n",
    "# signed int => unsigned int\n",
    "for i in range(10):\n",
    "    for j in range(192):\n",
    "        if int_fc_weight[i][j] < 0 :\n",
    "            int_fc_weight[i][j] += 256\n",
    "    if int_fc_bias[i] < 0 :\n",
    "        int_fc_bias[i] += 256*256 #16bit bias\n",
    "        \n",
    "print(int_fc_weight)\n",
    "print(int_fc_bias)\n",
    "\n",
    "np.savetxt('HW_fc_weight.mem', int_fc_weight, fmt='%1.2X',delimiter = \" \")\n",
    "np.savetxt('HW_fc_bias.mem', int_fc_bias, fmt='%1.2X',delimiter = \" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a077222d77dfe082b8f1dd562ad70e458ac2ab76993a0b248ab0476e32e9e8dd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
